import { ExperienceItem } from "@/types";

export const experiences: ExperienceItem[] = [
  {
    id: "afreximbank",
    role: "Manager, Data Scientist / Architect",
    roleFr: "Manager, Data Scientist / Architecte",
    organization: "African Export-Import Bank (Afreximbank)",
    location: "Cairo, Egypt",
    startDate: "Sep 2023",
    endDate: null,
    description: [
      "Designed and implemented end-to-end medallion architecture (Bronze/Silver/Gold) on Databricks with Delta Lake and Unity Catalog, establishing the enterprise data lakehouse foundation for all analytical and operational workloads",
      "Architected Master Data Management (MDM) solutions consolidating party data across four enterprise systems (CRM, Core Banking, Treasury Management, ERP), creating unified golden records for institutional counterparties",
      "Developed comprehensive data architecture blueprints including conceptual and logical data models, entity relationship diagrams, data dictionaries, and data flow documentation for mission-critical financial systems",
      "Created the enterprise data quality framework with automated metrics scripted on Databricks, monitoring completeness, consistency, timeliness, and accuracy across all data domains",
      "Led the selection and planned implementation of Ataccama as the enterprise data management platform, establishing data cataloging and metadata governance capabilities",
      "Built production-grade ETL/ELT pipelines extracting financial data from Oracle Finacle Core Banking System and Calypso Treasury Management System into PostgreSQL and Delta Lake targets",
      "Implemented Change Data Capture (CDC) and real-time streaming capabilities for data synchronization between treasury management systems and the enterprise data warehouse, enabling near-real-time risk monitoring and analytics",
      "Leveraged AWS services extensively: S3 for storage, Athena for serverless querying, Lambda for event-driven processing, RDS and Redshift for managed databases and warehousing, Kinesis for real-time streaming ML pipelines, SageMaker for model training and deployment, EC2 for compute – all orchestrated via boto3 SDK",
      "Established GitHub-based CI/CD pipelines for all data engineering workflows, ensuring version-controlled, reproducible, and auditable deployments across development, staging, and production environments",
      "Administered SAP Datasphere as the enterprise data warehousing platform, integrating structured and unstructured data sources across the organization",
      "Designed and deployed a multi-LLM enterprise chat platform (OpenAI, Claude, LLaMA, Gemini via AWS Bedrock and Databricks) with AI Agents and Text-to-SQL capabilities; built RAG pipelines with vector database architectures (FAISS) for automated document intelligence and knowledge retrieval",
      "Developed predictive analytics applications for real-time financial risk monitoring, counterparty risk scoring, and anomaly detection, delivering actionable intelligence to senior decision-makers",
      "Automated and enhanced the African Commodity Index and internal commodity dashboards across 54 African countries, improving consistency, reproducibility, and analytical depth",
      "Initiated the revamp of the methodological framework of the African Commodity Index to strengthen its analytical robustness and alignment with global best practices",
      "Built end-to-end ML and econometric modelling pipelines (Python, PySpark) for trade flow prediction, regional integration patterns, and cross-country macroeconomic forecasting using IMF DOTS, UNCTAD, and WTO datasets, with MLOps workflows via Databricks MLflow and GitHub CI/CD",
      "Improved research datasets through data quality processes, harmonisation, and methodological standardisation to support future econometric and policy analysis",
    ],
    descriptionFr: [
      "Conception et déploiement d'une architecture medallion de bout en bout (Bronze/Silver/Gold) sur Databricks avec Delta Lake et Unity Catalog, établissant le fondement du data lakehouse d'entreprise pour toutes les charges analytiques et opérationnelles",
      "Architecture de solutions MDM (Master Data Management) consolidant les données de contreparties à travers quatre systèmes d'entreprise (CRM, Core Banking, Treasury Management, ERP), créant des enregistrements unifiés « golden records » pour les contreparties institutionnelles",
      "Développement de blueprints complets d'architecture de données incluant modèles de données conceptuels et logiques, diagrammes entité-relation, dictionnaires de données et documentation des flux de données pour les systèmes financiers critiques",
      "Création du cadre de qualité des données d'entreprise avec des métriques automatisées scriptées sur Databricks, surveillant la complétude, la cohérence, la ponctualité et la précision à travers tous les domaines de données",
      "Direction de la sélection et planification de l'implémentation d'Ataccama comme plateforme de gestion des données d'entreprise, établissant les capacités de catalogage et de gouvernance des métadonnées",
      "Construction de pipelines ETL/ELT de production extrayant les données financières du système Core Banking Oracle Finacle et du système de gestion de trésorerie Calypso vers PostgreSQL et Delta Lake",
      "Implémentation du Change Data Capture (CDC) et des capacités de streaming en temps réel pour la synchronisation des données entre les systèmes de gestion de trésorerie et l'entrepôt de données d'entreprise, permettant le suivi et l'analytique des risques en quasi-temps réel",
      "Utilisation extensive des services AWS : S3 pour le stockage, Athena pour les requêtes serverless, Lambda pour le traitement événementiel, RDS et Redshift pour les bases de données et l'entreposage managés, Kinesis pour les pipelines ML en streaming temps réel, SageMaker pour l'entraînement et le déploiement de modèles, EC2 pour le calcul – le tout orchestré via le SDK boto3",
      "Mise en place de pipelines CI/CD basés sur GitHub pour tous les workflows d'ingénierie de données, garantissant des déploiements versionnés, reproductibles et auditables à travers les environnements de développement, staging et production",
      "Administration de SAP Datasphere comme plateforme d'entreposage de données d'entreprise, intégrant les sources de données structurées et non structurées à travers l'organisation",
      "Conception et déploiement d'une plateforme de chat multi-LLM d'entreprise (OpenAI, Claude, LLaMA, Gemini via AWS Bedrock et Databricks) avec des capacités d'Agents IA et de Text-to-SQL ; construction de pipelines RAG avec des architectures de bases vectorielles (FAISS) pour l'intelligence documentaire automatisée et la recherche de connaissances",
      "Développement d'applications d'analytique prédictive pour le suivi en temps réel des risques financiers, la notation des risques de contrepartie et la détection d'anomalies, fournissant de l'intelligence actionnable aux décideurs seniors",
      "Automatisation et amélioration de l'Indice Africain des Matières Premières et des tableaux de bord internes sur les matières premières à travers 54 pays africains, améliorant la cohérence, la reproductibilité et la profondeur analytique",
      "Initiation de la refonte du cadre méthodologique de l'Indice Africain des Matières Premières pour renforcer sa robustesse analytique et son alignement avec les meilleures pratiques mondiales",
      "Construction de pipelines de modélisation ML et économétrique de bout en bout (Python, PySpark) pour la prédiction des flux commerciaux, les schémas d'intégration régionale et les prévisions macroéconomiques inter-pays utilisant les données du FMI DOTS, CNUCED et OMC, avec des workflows MLOps via Databricks MLflow et GitHub CI/CD",
      "Amélioration des jeux de données de recherche à travers des processus de qualité des données, d'harmonisation et de standardisation méthodologique pour soutenir les futures analyses économétriques et politiques",
    ],
  },
  {
    id: "itu",
    role: "Data Engineer",
    roleFr: "Ingénieur de Données",
    organization: "International Telecommunication Union (ITU)",
    location: "Remote",
    startDate: "Dec 2024",
    endDate: "May 2025",
    description: [
      "Designed and implemented an automated ETL pipeline on Databricks to process heterogeneous infrastructure datasets from six countries (.csv, .xlsx, .gpkg, .tiff), enabling scalable multi-format data ingestion",
      "Developed a dynamic Data Quality (DQ) framework with rule-based checks (completeness, consistency, geographic integrity) and generated dual-format reports (.csv/.xlsx) with diagnostics and remediation guidance",
      "Integrated backend logic into the CPP toolkit frontend, enabling users to upload data, trigger preprocessing, and download reports via a seamless web interface",
      "Delivered YAML-based configuration for pipeline portability and no-code extensibility; coordinated full testing and deployment in shared compute environments",
      "Produced a video walkthrough and technical handover package for long-term sustainability and knowledge transfer",
    ],
    descriptionFr: [
      "Conception et implémentation d'un pipeline ETL automatisé sur Databricks pour traiter des jeux de données d'infrastructure hétérogènes provenant de six pays (.csv, .xlsx, .gpkg, .tiff), permettant une ingestion de données multi-formats évolutive",
      "Développement d'un cadre dynamique de qualité des données (DQ) avec des contrôles basés sur des règles (complétude, cohérence, intégrité géographique) et génération de rapports double format (.csv/.xlsx) avec diagnostics et conseils de remédiation",
      "Intégration de la logique backend dans le frontend du toolkit CPP, permettant aux utilisateurs de télécharger des données, déclencher le prétraitement et télécharger des rapports via une interface web fluide",
      "Livraison d'une configuration basée sur YAML pour la portabilité des pipelines et l'extensibilité sans code ; coordination des tests complets et du déploiement dans des environnements de calcul partagés",
      "Production d'un guide vidéo et d'un package de transfert technique pour la durabilité à long terme et le transfert de connaissances",
    ],
  },
  {
    id: "icco",
    role: "Statistician & Econometrician",
    roleFr: "Statisticien & Économètre",
    organization: "International Cocoa Organization (ICCO)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Apr 2017",
    endDate: "Sep 2023",
    description: [
      "Designed and maintained a tailored statistical database application serving as the organization's central data architecture for cocoa market intelligence, streamlining reporting workflows and ensuring data consistency across member countries",
      "Built forecasting models (ARIMA, VAR, VECM) to project global supply, demand, and pricing trends in the cocoa economy, directly informing strategic decisions for ICCO member countries and global stakeholders",
      "Authored and contributed to the Monthly Market Reports and the Quarterly Bulletin of Cocoa Statistics, establishing robust data pipelines for timely and accurate dissemination of market insights",
      "Led annual stock surveys across European warehouses to estimate regional and global end-of-season cocoa bean inventories, managing complex multi-site data collection and validation workflows",
      "Collected, validated, and harmonized global cocoa market data from multiple international sources (futures markets, national statistics, trade data), implementing data quality standards and governance processes",
      "Conducted econometric analyses of price volatility, supply–demand imbalances, and trade flow dynamics to produce evidence-based policy recommendations",
    ],
    descriptionFr: [
      "Conception et maintenance d'une application de base de données statistique sur mesure servant d'architecture centrale de données pour l'intelligence du marché du cacao, rationalisant les workflows de reporting et garantissant la cohérence des données entre les pays membres",
      "Construction de modèles de prévision (ARIMA, VAR, VECM) pour projeter les tendances mondiales de l'offre, de la demande et des prix dans l'économie du cacao, informant directement les décisions stratégiques des pays membres de l'ICCO et des parties prenantes mondiales",
      "Rédaction et contribution aux Rapports Mensuels du Marché et au Bulletin Trimestriel des Statistiques du Cacao, établissant des pipelines de données robustes pour une diffusion rapide et précise des informations de marché",
      "Direction des enquêtes annuelles de stocks dans les entrepôts européens pour estimer les inventaires régionaux et mondiaux de fèves de cacao en fin de saison, gérant des workflows complexes de collecte et validation de données multi-sites",
      "Collecte, validation et harmonisation des données mondiales du marché du cacao provenant de multiples sources internationales (marchés à terme, statistiques nationales, données commerciales), implémentant des normes de qualité des données et des processus de gouvernance",
      "Réalisation d'analyses économétriques de la volatilité des prix, des déséquilibres offre-demande et des dynamiques des flux commerciaux pour produire des recommandations politiques fondées sur les données",
    ],
  },
  {
    id: "unidir",
    role: "Researcher (Data Scientist / Statistician)",
    roleFr: "Chercheur (Data Scientist / Statisticien)",
    organization: "United Nations Institute for Disarmament Research (UNIDIR)",
    location: "Remote",
    startDate: "May 2023",
    endDate: "Aug 2023",
    description: [
      "Designed multi-country survey data architectures (Nigeria, Colombia, Iraq, Lake Chad Basin) for the MEAC disarmament and reintegration research project, managing end-to-end data pipelines",
      "Programmed and managed digital data collection via SurveyCTO with automated real-time quality control and validation rules; liaised with field teams on data consistency",
      "Led data cleaning, harmonization, and multivariate statistical analysis pipelines using R and STATA, producing evidence-based insights for post-conflict transition outcomes",
      "Delivered interactive dashboards and visualizations (Power BI) to support stakeholder engagement; ensured compliance with UN data governance and protection standards",
    ],
    descriptionFr: [
      "Conception d'architectures de données d'enquêtes multi-pays (Nigéria, Colombie, Irak, Bassin du Lac Tchad) pour le projet de recherche MEAC sur le désarmement et la réintégration, gérant les pipelines de données de bout en bout",
      "Programmation et gestion de la collecte de données numériques via SurveyCTO avec contrôle qualité automatisé en temps réel et règles de validation ; liaison avec les équipes de terrain sur la cohérence des données",
      "Direction du nettoyage, de l'harmonisation et des pipelines d'analyse statistique multivariée utilisant R et STATA, produisant des analyses fondées sur les données pour les résultats de transition post-conflit",
      "Livraison de tableaux de bord interactifs et de visualisations (Power BI) pour soutenir l'engagement des parties prenantes ; assurance de la conformité avec les normes de gouvernance et de protection des données de l'ONU",
    ],
  },
  {
    id: "iom",
    role: "Data Analyst Consultant",
    roleFr: "Consultant Analyste de Données",
    organization: "International Organization for Migration (IOM)",
    location: "Remote",
    startDate: "Apr 2022",
    endDate: "Nov 2022",
    description: [
      "Developed reproducible R scripts and markdown reports to analyze Migrant Health and Psychosocial Support (MHPSS) data across 8 West African countries, establishing standardized analytical pipelines",
      "Conducted impact evaluation analyses on migration in Guinea, The Gambia, Nigeria, and Senegal, delivering evidence-based findings for programme improvement",
      "Ensured analytical workflows were fully documented and automated for transparency and scalability across future assessments",
    ],
    descriptionFr: [
      "Développement de scripts R reproductibles et de rapports markdown pour analyser les données de Santé des Migrants et de Soutien Psychosocial (MHPSS) dans 8 pays d'Afrique de l'Ouest, établissant des pipelines analytiques standardisés",
      "Réalisation d'analyses d'évaluation d'impact sur la migration en Guinée, Gambie, Nigéria et Sénégal, fournissant des résultats fondés sur les données pour l'amélioration des programmes",
      "Assurance que les workflows analytiques étaient entièrement documentés et automatisés pour la transparence et l'évolutivité des évaluations futures",
    ],
  },
  {
    id: "unhcr",
    role: "KoboToolBox Consultant",
    roleFr: "Consultant KoboToolBox",
    organization: "United Nations High Commissioner for Refugees (UNHCR)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Dec 2016",
    endDate: "Feb 2017",
    description: [
      "Designed and implemented a digital data collection system using KoboToolBox to support field operations and monitoring activities for refugee programmes",
      "Trained field personnel on effective use of online data collection tools and ensured smooth transition from paper-based methods to digital workflows",
      "Digitized all existing UNHCR Côte d'Ivoire data collection instruments and provided ongoing technical guidance to ensure data integrity and reporting consistency",
    ],
    descriptionFr: [
      "Conception et implémentation d'un système de collecte de données numériques utilisant KoboToolBox pour soutenir les opérations de terrain et les activités de suivi des programmes pour les réfugiés",
      "Formation du personnel de terrain sur l'utilisation efficace des outils de collecte de données en ligne et assurance d'une transition fluide des méthodes papier vers les workflows numériques",
      "Numérisation de tous les instruments de collecte de données existants du HCR Côte d'Ivoire et fourniture de conseils techniques continus pour garantir l'intégrité des données et la cohérence des rapports",
    ],
  },
  {
    id: "barry-callebaut",
    role: "Monitoring & Evaluation Manager",
    roleFr: "Responsable Suivi & Évaluation",
    organization: "Barry-Callebaut (SACO)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Aug 2016",
    endDate: "Apr 2017",
    description: [
      "Designed and managed the geotraceability data collection system for the Cocoa Horizons program, architecting data flows from field surveys through to analytical dashboards",
      "Built and maintained master data systems for farmer organizations; defined and monitored KPIs through dashboards to inform strategic decision-making",
      "Delivered a full M&E framework including data architecture, survey design, field execution, impact evaluation protocols, and progress tracking systems",
      "Conducted fieldwork on cocoa demo plots and fermentation practices to evaluate agronomic innovations, combining field statistics with geospatial data collection",
    ],
    descriptionFr: [
      "Conception et gestion du système de collecte de données de géotraçabilité pour le programme Cocoa Horizons, architecturant les flux de données des enquêtes de terrain jusqu'aux tableaux de bord analytiques",
      "Construction et maintenance des systèmes de données maîtres pour les organisations de producteurs ; définition et suivi de KPI via des tableaux de bord pour éclairer la prise de décision stratégique",
      "Livraison d'un cadre complet de S&E incluant architecture de données, conception d'enquêtes, exécution terrain, protocoles d'évaluation d'impact et systèmes de suivi des progrès",
      "Réalisation de travaux de terrain sur les parcelles de démonstration cacao et les pratiques de fermentation pour évaluer les innovations agronomiques, combinant statistiques de terrain et collecte de données géospatiales",
    ],
  },
  {
    id: "icrisat",
    role: "Consultant",
    roleFr: "Consultant",
    organization: "International Crops Research Institute for the Semi-Arid Tropics (ICRISAT)",
    location: "Bamako, Mali",
    startDate: "Jul 2016",
    endDate: "Jul 2016",
    description: [
      "Facilitated hands-on training for multidisciplinary research professionals on the use of Open Data Kit (ODK) and Cspro for digital survey design and data collection",
      "Introduced participants to statistical packages (R, STATA) for analyzing experimental and survey data",
      "Delivered practical case exercises to enhance participants' analytical and data management skills",
    ],
    descriptionFr: [
      "Animation de formations pratiques pour des professionnels de recherche multidisciplinaires sur l'utilisation d'Open Data Kit (ODK) et Cspro pour la conception d'enquêtes numériques et la collecte de données",
      "Introduction des participants aux logiciels statistiques (R, STATA) pour l'analyse de données expérimentales et d'enquêtes",
      "Livraison d'exercices pratiques de cas pour renforcer les compétences analytiques et de gestion des données des participants",
    ],
  },
  {
    id: "fhi360",
    role: "Monitoring & Evaluation Officer",
    roleFr: "Chargé de Suivi & Évaluation",
    organization: "Family Health International (FHI360)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Nov 2015",
    endDate: "Jul 2016",
    description: [
      "Designed evaluation analysis plans and developed STATA-based scripts for automated data processing across multiple public health projects",
      "Contributed to the development of four impact evaluation protocols and co-authored a peer-reviewed article on adolescent behavioral health",
      "Drafted statistical sections of research protocols, study reports, and manuscripts; provided technical and statistical support for M&E activities",
    ],
    descriptionFr: [
      "Conception de plans d'analyse d'évaluation et développement de scripts basés sur STATA pour le traitement automatisé des données à travers de multiples projets de santé publique",
      "Contribution au développement de quatre protocoles d'évaluation d'impact et co-rédaction d'un article évalué par les pairs sur la santé comportementale des adolescents",
      "Rédaction des sections statistiques des protocoles de recherche, rapports d'études et manuscrits ; fourniture d'un soutien technique et statistique pour les activités de S&E",
    ],
  },
  {
    id: "icraf",
    role: "Data Manager",
    roleFr: "Gestionnaire de Données",
    organization: "International Centre for Research in Agroforestry (ICRAF)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Jun 2013",
    endDate: "Oct 2015",
    description: [
      "Designed and implemented M&E data architectures for agroforestry research projects; developed and maintained relational databases (Access, PostgreSQL) to monitor performance indicators",
      "Conducted 10+ household studies (baselines, midterms, endlines) across West Africa; migrated data collection workflows from paper to digital systems using Open Data Kit",
      "Automated data analysis and reporting pipelines using R, Excel, and Access; trained research teams in Kenya and Côte d'Ivoire on data quality best practices",
      "Managed complex experimental and survey datasets; performed advanced statistical analyses using R and STATA for peer-reviewed research outputs",
    ],
    descriptionFr: [
      "Conception et implémentation d'architectures de données S&E pour les projets de recherche en agroforesterie ; développement et maintenance de bases de données relationnelles (Access, PostgreSQL) pour le suivi des indicateurs de performance",
      "Réalisation de plus de 10 études auprès des ménages (référence, mi-parcours, fin de projet) à travers l'Afrique de l'Ouest ; migration des workflows de collecte de données du papier vers des systèmes numériques utilisant Open Data Kit",
      "Automatisation des pipelines d'analyse de données et de reporting utilisant R, Excel et Access ; formation des équipes de recherche au Kenya et en Côte d'Ivoire sur les meilleures pratiques de qualité des données",
      "Gestion de jeux de données expérimentales et d'enquêtes complexes ; réalisation d'analyses statistiques avancées utilisant R et STATA pour des publications de recherche évaluées par les pairs",
    ],
  },
  {
    id: "pac-ci",
    role: "Data Manager",
    roleFr: "Gestionnaire de Données",
    organization: "Programme ANRS Coopération Côte d'Ivoire (PAC-CI)",
    location: "Abidjan, Côte d'Ivoire",
    startDate: "Nov 2012",
    endDate: "Jun 2013",
    description: [
      "Harmonized 16 epidemiological datasets from 8 West African countries for the IeDEA consortium, designing cross-country data integration architecture for HIV/AIDS research",
      "Automated key project indicators reporting using custom-built SQL and VBA scripts, reducing manual effort and improving reproducibility",
      "Conducted rigorous data quality assurance, validation, and consistency checks prior to submission to the regional hub in Bordeaux, France",
    ],
    descriptionFr: [
      "Harmonisation de 16 jeux de données épidémiologiques provenant de 8 pays d'Afrique de l'Ouest pour le consortium IeDEA, concevant une architecture d'intégration de données inter-pays pour la recherche sur le VIH/SIDA",
      "Automatisation du reporting des indicateurs clés du projet à l'aide de scripts SQL et VBA personnalisés, réduisant l'effort manuel et améliorant la reproductibilité",
      "Réalisation d'assurance qualité rigoureuse des données, de validation et de contrôles de cohérence avant soumission au hub régional de Bordeaux, France",
    ],
  },
];
